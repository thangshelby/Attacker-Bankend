import json
from .base_agent import BaseAgent
from llama_index.llms.openai import OpenAI
import os
import re


class DecisionAgent(BaseAgent):
    def __init__(self, name="DecisionAgent", coordinator=None):
        super().__init__(name, coordinator)
        self.responses = []  # L∆∞u c√°c ph·∫£n h·ªìi t·ª´ c√°c agent kh√°c

    def handle_message(self, message: dict):
        """
        Nh·∫≠n ph·∫£n h·ªìi t·ª´ c√°c agent kh√°c v√† t·ªïng h·ª£p ƒë·ªÉ ƒë∆∞a ra quy·∫øt ƒë·ªãnh cu·ªëi c√πng.
        """
        message_type = message.get("type")
        sender = message.get("sender")
        payload = message.get("payload", {})

        # Nh·∫≠n ph·∫£n h·ªìi t·ª´ c√°c agent kh√°c
        if message_type in ["loan_decision", "scholarship_decision", "loan_decision_critical_response", "scholarship_decision_critical_response"]:
            self.responses.append({"from": sender, "type": message_type, "payload": payload})
            print(f"[{self.name}] ƒê√£ nh·∫≠n ph·∫£n h·ªìi t·ª´ {sender}: {payload}")
        elif message_type == "aggregate_and_decide":
            # Khi nh·∫≠n l·ªánh t·ªïng h·ª£p, ph√¢n t√≠ch c√°c ph·∫£n h·ªìi v√† ƒë∆∞a ra quy·∫øt ƒë·ªãnh cu·ªëi c√πng
            final_decision = self.aggregate_decisions()
            self.send_message(message.get("sender", "user"), "final_decision", final_decision)
        elif message_type == "aggregate_all":
            # Khi nh·∫≠n t·∫•t c·∫£ ph·∫£n h·ªìi g·ªôp, t·ªïng h·ª£p v√† ra quy·∫øt ƒë·ªãnh
            final_decision = self.aggregate_all(payload)
            self.send_message(message.get("sender", "user"), "final_decision", final_decision)
        else:
            print(f"[{self.name}] Kh√¥ng h·ªó tr·ª£ message type: {message_type}")
            
    def extract_rule_features_from_profile(self, profile_text):
        """
        Tr√≠ch xu·∫•t rule-based features t·ª´ profile text.
        TRICK: Convert subjective data th√†nh objective rule compliance!
        """
        if not profile_text:
            return self._get_default_features()
            
        # Extract GPA v·ªõi nhi·ªÅu pattern kh√°c nhau
        gpa_patterns = [
            r'GPA[:\s]*chu·∫©n[:\s]*h√≥a[:\s]*([0-9]+\.?[0-9]*)',  # "GPA chu·∫©n h√≥a: 0.72"
            r'GPA[:\s]*([0-9]+\.?[0-9]*)',                     # "GPA: 7.25" ho·∫∑c "GPA 0.717"
            r'ƒëi·ªÉm[:\s]*trung[:\s]*b√¨nh[:\s]*([0-9]+\.?[0-9]*)', # "ƒëi·ªÉm trung b√¨nh"
        ]
        
        gpa_raw = 5.0  # Default 5.0/10
        gpa_found_pattern = None
        
        for i, pattern in enumerate(gpa_patterns):
            gpa_match = re.search(pattern, profile_text, re.IGNORECASE)
            if gpa_match:
                gpa_raw = float(gpa_match.group(1))
                gpa_found_pattern = f"pattern_{i+1}"
                break
        
        # Convert thang 10 ‚Üí thang 1
        if gpa_raw > 1:  # Thang 10 (like 7.25, 6.42, 8.5)
            gpa_normalized = gpa_raw / 10.0
        else:  # ƒê√£ l√† thang 1 (like 0.725, 0.85)
            gpa_normalized = gpa_raw
            

            
        # Extract University Tier
        tier_match = re.search(r'tier[:\s]*([1-5])', profile_text, re.IGNORECASE)
        university_tier = int(tier_match.group(1)) if tier_match else 3
        
        # Extract Major
        major_keywords = ['STEM', 'Y khoa', 'IT', 'S∆∞ ph·∫°m', 'Computer', 'Engineering', 'Medicine', 'Science']
        major_priority = any(keyword.lower() in profile_text.lower() for keyword in major_keywords)
        
        # Extract Public University (feature_3_truong_hoc)
        is_public_university = 'tr∆∞·ªùng c√¥ng l·∫≠p' in profile_text.lower()
        
        # Extract Guarantor (feature_5_bao_lanh)
        # Dataset logic: "Kh√¥ng c√≥" = kh√¥ng c√≥ b·∫£o l√£nh (False), m·ªçi gi√° tr·ªã kh√°c = c√≥ b·∫£o l√£nh (True)
        has_guarantor = True  # Default assume c√≥ b·∫£o l√£nh
        
        # Check for explicit "Kh√¥ng c√≥" patterns
        no_guarantor_patterns = [
            'b·∫£o l√£nh: kh√¥ng c√≥',
            'ng∆∞·ªùi b·∫£o l√£nh: kh√¥ng c√≥', 
            'kh√¥ng c√≥ ng∆∞·ªùi b·∫£o l√£nh',
            ': kh√¥ng c√≥'  # Generic pattern
        ]
        
        for pattern in no_guarantor_patterns:
            if pattern in profile_text.lower():
                has_guarantor = False
                break
        
        # Extract Income (in VND) - Format: "Thu nh·∫≠p 8,000,000 VND/th√°ng"
        income_patterns = [
            r'thu nh·∫≠p[:\s]*([0-9,\.]+)\s*VND/th√°ng',  # Exact format from profile
            r'thu nh·∫≠p[:\s]*([0-9,\.]+)\s*VND',
            r'([0-9,\.]+)\s*VND/th√°ng',
            r'thu nh·∫≠p[:\s]*([0-9,\.]+)\s*(?:tri·ªáu|M)',  # Backup patterns
        ]
        family_income = 15000000  # Default (conservative high income)
        
        for pattern in income_patterns:
            income_match = re.search(pattern, profile_text, re.IGNORECASE)
            if income_match:
                income_str = income_match.group(1).replace(',', '').replace('.', '')
                try:
                    income_val = int(income_str)  # Use int instead of float
                    # If value is reasonable (> 100,000), use as-is
                    if income_val >= 100000:  # Assume already in VND
                        family_income = income_val
                    elif income_val < 1000:  # Likely in millions
                        family_income = income_val * 1000000
                    else:
                        family_income = income_val
                    print(f"[DecisionAgent] üí∞ Extracted family_income: {family_income:,} VND")
                    break
                except ValueError:
                    continue  # Try next pattern
                
        # Extract Debt Status - c·∫ßn ph√¢n bi·ªát "ƒêang c√≥ n·ª£" vs "Kh√¥ng c√≥ n·ª£"
        debt_positive_keywords = ['ƒëang c√≥ n·ª£', 'hi·ªán c√≥ n·ª£', 'c√≥ n·ª£ hi·ªán t·∫°i']
        debt_negative_keywords = ['kh√¥ng c√≥ n·ª£', 'kh√¥ng c√≥ n·ª£ n·∫ßn', 'ch∆∞a c√≥ n·ª£']
        
        profile_lower = profile_text.lower()
        has_positive_debt = any(keyword in profile_lower for keyword in debt_positive_keywords)
        has_negative_debt = any(keyword in profile_lower for keyword in debt_negative_keywords)
        
        if has_positive_debt:
            has_debt = True
        elif has_negative_debt:
            has_debt = False
        else:
            # Fallback: check for general debt keywords
            has_debt = any(keyword in profile_lower for keyword in ['debt', 'n·ª£']) and not any(neg in profile_lower for neg in ['kh√¥ng', 'ch∆∞a'])
        
        # Extract Loan Amount
        loan_patterns = [
            r'vay[:\s]*([0-9,\.]+)\s*(?:tri·ªáu|M|VND)',
            r'([0-9,\.]+)\s*(?:tri·ªáu|M)\s*VND.*(?:vay|loan)'
        ]
        loan_amount = 50000000  # Default
        for pattern in loan_patterns:
            loan_match = re.search(pattern, profile_text, re.IGNORECASE)
            if loan_match:
                loan_str = loan_match.group(1).replace(',', '').replace('.', '')
                loan_val = float(loan_str)
                if loan_val < 1000:  # Likely in millions
                    loan_val *= 1000000
                loan_amount = loan_val
                break
        
        # Apply RULE-BASED LOGIC (QUY ƒê·ªäNH 2025)
        feature_1_thu_nhap = family_income <= 8000000  # Thu nh·∫≠p ‚â§ 10M = ∆∞u ti√™n (PASS)
        feature_2_hoc_luc = gpa_normalized >= 0.65  # SPECIAL
        feature_3_truong_hoc = is_public_university  # UPDATED: Tr∆∞·ªùng c√¥ng l·∫≠p = PASS
        feature_4_nganh_uu_tien = major_priority
        feature_5_bao_lanh = has_guarantor  # UPDATED: C√≥ ng∆∞·ªùi b·∫£o l√£nh = PASS
        feature_6_khoan_vay = loan_amount <= 60000000 or loan_amount <= 3000000 * 12  # per year
        feature_7_no_existing_debt = not has_debt  # SPECIAL - existing_debt=false (kh√¥ng c√≥ n·ª£) = PASS
        
        # Debug log features
        print(f"[DecisionAgent] üîç Feature Analysis:")
        print(f"  F1 Thu nh·∫≠p: {family_income:,} VND ‚â§ 10M? ‚Üí {feature_1_thu_nhap}")
        print(f"  F2 H·ªçc l·ª±c: GPA {gpa_normalized:.2f} ‚â• 0.7? ‚Üí {feature_2_hoc_luc}")  
        print(f"  F3 Tr∆∞·ªùng h·ªçc: C√¥ng l·∫≠p? ‚Üí {feature_3_truong_hoc}")
        print(f"  F4 Ng√†nh ∆∞u ti√™n: STEM/Y khoa? ‚Üí {feature_4_nganh_uu_tien}")
        print(f"  F5 B·∫£o l√£nh: C√≥ ng∆∞·ªùi b·∫£o l√£nh? ‚Üí {feature_5_bao_lanh}")
        print(f"  F6 Kho·∫£n vay: {loan_amount:,} VND ‚â§ 60M? ‚Üí {feature_6_khoan_vay}")
        print(f"  F7 Kh√¥ng n·ª£: Kh√¥ng c√≥ n·ª£ hi·ªán t·∫°i? ‚Üí {feature_7_no_existing_debt}")
        
        return {
            'feature_1_thu_nhap': feature_1_thu_nhap,
            'feature_2_hoc_luc': feature_2_hoc_luc,
            'feature_3_truong_hoc': feature_3_truong_hoc,
            'feature_4_nganh_uu_tien': feature_4_nganh_uu_tien,
            'feature_5_bao_lanh': feature_5_bao_lanh,
            'feature_6_khoan_vay': feature_6_khoan_vay,
            'feature_7_no_existing_debt': feature_7_no_existing_debt
        }
    
    def _get_default_features(self):
        """Default conservative features when profile parsing fails"""
        return {
            'feature_1_thu_nhap': False,    # Thu nh·∫≠p cao (conservative)
            'feature_2_hoc_luc': False,     # GPA th·∫•p (conservative)
            'feature_3_truong_hoc': False,  # Tr∆∞·ªùng t∆∞ th·ª•c (conservative)
            'feature_4_nganh_uu_tien': False, # Ng√†nh kh√¥ng ∆∞u ti√™n (conservative)
            'feature_5_bao_lanh': False,    # "Kh√¥ng c√≥" b·∫£o l√£nh (conservative)
            'feature_6_khoan_vay': False,   # S·ªë ti·ªÅn vay cao (conservative)
            'feature_7_no_existing_debt': False  # C√≥ n·ª£ hi·ªán t·∫°i (conservative)
        }

    def aggregate_all(self, merged_payload):
        """
        HYBRID APPROACH: Subjective debate ‚Üí Objective rule-based decision
        """
        # SAFETY CHECK
        if not merged_payload or not isinstance(merged_payload, dict):
            return {
                "decision": "reject",
                "reason": "L·ªói h·ªá th·ªëng: Kh√¥ng nh·∫≠n ƒë∆∞·ª£c d·ªØ li·ªáu t·ª´ agents",
                "rule_based_system": True,
                "error": "invalid_payload"
            }
        
        print(f"[DecisionAgent] HYBRID DECISION: Converting subjective ‚Üí objective rules")
        
        # Get original profile for accurate rule-based feature extraction
        original_profile = merged_payload.get("original_profile", "")
        academic_data = merged_payload.get("scholarship_decision") or {}
        finance_data = merged_payload.get("loan_decision") or {}
        
        # ALWAYS use original profile for rule extraction (ignore agent reasoning)
        if original_profile:
            profile_for_extraction = original_profile
            print(f"[DecisionAgent] ‚úÖ Using ORIGINAL profile for rule extraction")
        else:
            # EMERGENCY: original_profile missing - reject by default
            print(f"[DecisionAgent] ‚ùå MISSING original_profile - using conservative defaults")
            return {
                "decision": "reject",
                "reason": "L·ªói h·ªá th·ªëng: Thi·∫øu th√¥ng tin profile g·ªëc ƒë·ªÉ √°p d·ª•ng quy ƒë·ªãnh",
                "rule_based_system": True,
                "error": "missing_original_profile"
            }
        
        # CONVERT SUBJECTIVE TO OBJECTIVE RULES
        features = self.extract_rule_features_from_profile(profile_for_extraction)
        
        # √ÅP D·ª§NG CH√çNH X√ÅC QUY ƒê·ªäNH 2025
        all_features = [
            features['feature_1_thu_nhap'],    # Feature 1
            features['feature_2_hoc_luc'],     # Feature 2 (SPECIAL)
            features['feature_3_truong_hoc'],  # Feature 3
            features['feature_4_nganh_uu_tien'], # Feature 4
            features['feature_5_bao_lanh'],    # Feature 5 (SPECIAL)
            features['feature_6_khoan_vay'],   # Feature 6
            features['feature_7_no_existing_debt'] # Feature 7 (SPECIAL) - Kh√¥ng c√≥ n·ª£
        ]
        
        # T√≠nh passed_count = s·ªë feature passed (True)
        passed_count = sum(all_features)
        
        # T√≠nh special_violations = s·ªë failed (False) trong [2,5,7]
        special_features = [features['feature_2_hoc_luc'], features['feature_5_bao_lanh'], features['feature_7_no_existing_debt']]
        special_violations = sum(1 for f in special_features if not f)
        
        # LOGIC QUY·∫æT ƒê·ªäNH THEO QUY ƒê·ªäNH 2025 (S·ª¨A L·ªñI)
        if special_violations > 1:
            decision = "reject"
            reason = f"Vi ph·∫°m {special_violations} special features (F2,F5,F7) - T·ª∞ ƒê·ªòNG T·ª™ CH·ªêI theo quy ƒë·ªãnh."
        elif special_violations == 1:
            if passed_count >= 6:
                decision = "approve"
                reason = f"Vi ph·∫°m 1 special feature nh∆∞ng passed_count = {passed_count} >= 6 - CH·∫§P NH·∫¨N c√≥ ƒëi·ªÅu ki·ªán."
            else:
                decision = "reject"
                reason = f"Vi ph·∫°m 1 special feature v√† passed_count = {passed_count} < 6 - T·ª™ CH·ªêI."
        else:  # special_violations == 0 - PASS C·∫¢ 3 SPECIAL FEATURES
            decision = "approve"
            reason = f"PASS c·∫£ 3 special features (F2,F5,F7) - T·ª∞ ƒê·ªòNG CH·∫§P NH·∫¨N (passed_count = {passed_count}/7)."
        
        # Th√™m th√¥ng tin chi ti·∫øt
        detailed_analysis = {
            "features_analysis": features,
            "rule_calculation": {
                "total_passed_count": passed_count,
                "special_violations_count": special_violations,
                "special_features_status": {
                    "feature_2": features['feature_2_hoc_luc'],
                    "feature_5": features['feature_5_bao_lanh'],
                    "feature_7": features['feature_7_no_existing_debt']
                }
            },
            "regulation_compliance": "Ngh·ªã ƒë·ªãnh 07/2021/Nƒê-CP, Quy·∫øt ƒë·ªãnh 05/2022/Qƒê-TTg, Th√¥ng t∆∞ 19/2023/TT-BGDƒêT (c·∫≠p nh·∫≠t 2025)",
            "subjective_inputs": {
                "academic_decision": academic_data.get("decision") if academic_data else None,
                "finance_decision": finance_data.get("decision") if finance_data else None,
                "academic_reason": academic_data.get("reason") if academic_data else None,
                "finance_reason": finance_data.get("reason") if finance_data else None
            }
        }
        
        result = {
            "decision": decision,
            "reason": reason,
            "detailed_analysis": detailed_analysis,
            "rule_based_system": True,
            "hybrid_approach": "subjective_debate_to_objective_rules"
        }
        
        print(f"[{self.name}] HYBRID QUY·∫æT ƒê·ªäNH: {result}")
        return result

    def aggregate_decisions(self):
        """
        Legacy method - gi·ªØ l·∫°i ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi workflow c≈©
        """
        # Gom h·ªôi tho·∫°i c√°c agent
        dialogue = []
        for resp in self.responses:
            who = resp["from"]
            payload = resp["payload"]
            if isinstance(payload, dict):
                decision = payload.get("decision", "")
                reason = payload.get("reason", "")
                risk_level = payload.get("risk_level", "")
                
                line = f"{who}: {decision.upper()}"
                if risk_level:
                    line += f" (risk: {risk_level})"
                line += f" - {reason}"
                dialogue.append(line)
            elif isinstance(payload, str):
                dialogue.append(f"{who}: {payload}")

        dialogue_text = "\n".join(dialogue)
        prompt = (
            "B·∫°n l√† DECISION MAKER √°p d·ª•ng QUY ƒê·ªäNH 2025 v·ªÅ vay v·ªën sinh vi√™n.\n"
            "D·ª±a tr√™n ph√¢n t√≠ch subjective t·ª´ c√°c agents, ƒë∆∞a ra quy·∫øt ƒë·ªãnh cu·ªëi c√πng:\n\n"
            f"Ph√¢n t√≠ch t·ª´ agents:\n{dialogue_text}\n\n"
            "H∆Ø·ªöNG D·∫™N QUY·∫æT ƒê·ªäNH:\n"
            "- T·ªïng h·ª£p √Ω ki·∫øn subjective\n"
            "- C√¢n b·∫±ng academic potential vs financial risk\n"
            "- Xem x√©t critiques c√≥ h·ª£p l√Ω kh√¥ng\n"
            "- Quy·∫øt ƒë·ªãnh c√¥ng b·∫±ng v√† c√≥ l√Ω\n\n"
            "QUAN TR·ªåNG: Ch·ªâ tr·∫£ l·ªùi JSON h·ª£p l·ªá:\n"
            '{"decision": "approve" ho·∫∑c "reject", "reason": "<l√Ω do chi ti·∫øt>"}'
        )
        
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("[DecisionAgent] OPENAI_API_KEY kh√¥ng ƒë∆∞·ª£c t√¨m th·∫•y trong m√¥i tr∆∞·ªùng.")
            return {"decision": "reject", "reason": "Kh√¥ng c√≥ API key cho LLM."}
            
        llm = OpenAI(api_key=api_key, model='gpt-4.1-nano')
        try:
            response_text = llm.complete(prompt, max_tokens=512)
            response_data = json.loads(str(response_text))
            print(f"[{self.name}] QUY·∫æT ƒê·ªäNH CU·ªêI C√ôNG (Legacy): {response_data}")
            return response_data
        except Exception as e:
            print(f"[{self.name}] L·ªói khi t·ªïng h·ª£p quy·∫øt ƒë·ªãnh: {e}")
            return {"decision": "reject", "reason": f"L·ªói t·ªïng h·ª£p quy·∫øt ƒë·ªãnh: {e}"}

    def send_message(self, recipient, message_type, payload):
        if self.coordinator:
            self.coordinator.route_message(self.name, recipient, message_type, payload)
        else:
            print(f"[{self.name}] (Test) G·ª≠i t·ªõi {recipient} | type: {message_type} | payload: {payload}")

if __name__ == "__main__":
    # Test hybrid approach
    agent = DecisionAgent()
    test_payload = {
        "scholarship_decision": {
            "decision": "approve",
            "reason": "GPA 0.85 xu·∫•t s·∫Øc, STEM tier 1, c√≥ CLB"
        },
        "loan_decision": {
            "decision": "approve", 
            "reason": "Thu nh·∫≠p 8M VND/th√°ng, kh√¥ng n·ª£, vay 45M h·ªçc ph√≠",
            "risk_level": "low"
        }
    }
    
    agent.handle_message({
        "type": "aggregate_all",
        "sender": "tester",
        "payload": test_payload
    })
